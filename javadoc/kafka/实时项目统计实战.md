# 实时项目统计实战


## 一、需求说明

* 今天到现在为止的每个类别的访问量
* 今天到现在为止从搜索引擎引流过来的类别的访问量
* 今天到现在为止每个栏目下面的销售额
* 今天到现在为止每个省份的购买量


![image](https://github.com/csy512889371/learnDoc/blob/master/image/2018/spark/1.png)

项目使用的技术点


![image](https://github.com/csy512889371/learnDoc/blob/master/image/2018/spark/2.png)

javaweb log -> flume -> kafka -> sparkStreaming -> Hbase -> Spring boot -> echart


## 二、互联网访问日志概述

### 1、为什么要记录访问日志的行为呢？

* 通过日志我们可以得到网站页面的访问量，网站的黏性，推荐
* 用户行为分析，是指在获得网站访问量基本数据的情况下，对有关数据进行统计、分析，从中发现用户访问网站的规律，并将这些规律与网络营销策略等相结合，从而发现目前网络营
销活动中可能存在的问题，并为进一步修正或重新制定网络营销策略提供依据。这是狭义的只指网络上的用户行为分析。


### 2、重点分析的数据

用户行为分析应该包含以下数据重点分析：

* 用户的来源地区、来路域名和页面；
* 用户在网站的停留时间、跳出率、回访者、新访问者、回访次数、回访相隔天数；
* 注册用户和非注册用户，分析两者之间的浏览习惯；
* 用户所使用的搜索引擎、关键词、关联关键词和站内关键字；
* 用户选择什么样的入口形式（广告或者网站入口链接）更为有效；
* 用户访问网站流程，用来分析页面结构设计是否合理；
* 用户在页面上的网页热点图分布数据和网页覆盖图数据；
* 用户在不同时段的访问量情况等： 
* 用户对于网站的字体颜色的喜好程度。


### 3、日志格式字段：

```
ip 地址 用户名 访问时间 访问的模块地址 使用的方式 .....
```

意义:

通过对用户行为监测获得的数据进行分析，可以让企业更加详细、清楚地了解用户的行为习惯，从而找出网站、推广渠道等企业营销环境存在的问题，有助于企业发掘高转化率页面，让企业的营销更加精准、有效，提高业务转化率，从而提升企业的广告收益。

### 4、日志分析

```
www/2 --代表电视剧
www/1 --代表电影
www/6 --综艺
www/4 -- 动漫
www/3 -- 记录篇

```

### 5、使用 Python 脚本实时产生数据


因为我们要使用实时数据，不可能从主站拿到，只能模仿，我们一般使用是脚本 python 或者 java


generate.py

```
# coding=UTF-8
import random
import time

url_paths = [
    "www/2",
    "www/1",
    "www/6",
    "www/4",
    "www/3",
    "pianhua/130",
    "toukouxu/821"
]

status_code = [404, 302, 200]

ip_slices = [132, 156, 124, 10, 29, 167, 143, 187, 30, 100]

http_referers = [
    "https://www.baidu.com/s?wd={query}",
    "https://www.sogou.com/web?qu={query}",
    "http://cn.bing.com/search?q={query}",
    "https://search.yahoo.com/search?p={query}"
]

search_keyword = [
    "猎场",
    "快乐人生",
    "极限挑战",
    "我的体育老师",
    "幸福满院"
]


# ip地址
def sample_ip():
    slice = random.sample(ip_slices, 4)
    return ".".join([str(item) for item in slice])


def sample_url():
    return random.sample(url_paths, 1)[0]


def sample_status():
    return random.sample(status_code, 1)[0]


def sample_referer():
    if random.uniform(0, 1) > 0.2:
        return "-"
    refer_str = random.sample(http_referers, 1)
    # print refer_str[0]
    query_str = random.sample(search_keyword, 1)
    # print query_str[0]
    return refer_str[0].format(query=query_str[0])


# 产生log
def generate_log(count=10):
    time_str = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
    f = open("F:\\api\\logs\log.txt","w+")
    # f = open("/home/centos/log/log", "a+")
    while count >= 1:
        query_log = "{ip}\t{localtime}\t\"GET {url} HTTP/1.0\"\t{referece}\t{status1}".format(ip=sample_ip(),
                                                                                              url=sample_url(),
                                                                                              status1=sample_status(),
                                                                                              referece=sample_referer(),
                                                                                              localtime=time_str)
        # print query_log
        f.write(query_log + "\n")
        count = count - 1;


if __name__ == '__main__':
    generate_log(100)
# print "1111"

```

python 3

```
python generate.py

```


生成的结果：

```
30.29.187.10	2018-05-04 11:42:16	"GET www/2 HTTP/1.0"	-	302
187.30.167.143	2018-05-04 11:42:16	"GET www/2 HTTP/1.0"	-	404
30.143.187.124	2018-05-04 11:42:16	"GET toukouxu/821 HTTP/1.0"	-	200
132.187.167.100	2018-05-04 11:42:16	"GET www/4 HTTP/1.0"	https://www.baidu.com/s?wd=快乐人生	200
124.187.29.100	2018-05-04 11:42:16	"GET pianhua/130 HTTP/1.0"	-	200
30.143.187.124	2018-05-04 11:42:16	"GET www/6 HTTP/1.0"	-	404
29.167.187.132	2018-05-04 11:42:16	"GET www/1 HTTP/1.0"	https://www.baidu.com/s?wd=极限挑战	302
187.10.29.132	2018-05-04 11:42:16	"GET www/1 HTTP/1.0"	-	302
187.30.156.29	2018-05-04 11:42:16	"GET toukouxu/821 HTTP/1.0"	-	302
```


### 5、通过调度器工具每一分钟产生一批数据

linux crontab 



